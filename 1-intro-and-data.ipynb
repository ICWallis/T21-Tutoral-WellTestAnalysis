{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "QNAABJ4WTK6kjlrofclR",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "***\n",
    "\n",
    "# Geothermal Well Test Analysis with Python\n",
    "### Notebook 1: Introduction and Data Preparation \n",
    "#### Irene Wallis and Katie McLean \n",
    "#### Software Underground, Transform 2021\n",
    "***\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "#### Tutorial overview\n",
    "\n",
    "In this tutorial, we provide an overview of geothermal wells, well testing in general, and the types of data that are captured during completion testing. We then step though a completion test analysis workflow including:\n",
    "- Import, formatting and cleaning of pressure, temperature and spinner log (PTS) data and the assocated pump data\n",
    "- Extraction and plotting of selected temperature logs\n",
    "- Interpolation of injectivity index from pressure and pump flowrate data\n",
    "- Detection of feed zones through spinner analysis\n",
    "\n",
    "Completion testing involves the capture of a large volume of data, which can be cumbersome to analyse in Excel. During this tutoral, we demonstrate efficient and agile processing of these data using Python. Working inside the Jupyter Notebook environment also enables us to generate an annotated record of our work that can be easily repeated or audited, which is worthwhile considering the high-value decisions that are based on completion test analysis. [Jupyter Lab](https://jupyterlab.readthedocs.io/en/stable/user/export.html) and [VS Studio Code](https://code.visualstudio.com/docs/python/jupyter-support) both enable exporting these Jupyter Notebooks to formats more typically used for reports, such as HTML or pdf. \n",
    "\n",
    "#### Reuse of the materal in this tutorial\n",
    "\n",
    "We have made this workflow open-source under the Apache 2.0 licence, which is a permissive licence that allows reuse in your own work with attribution to the original authors. If you alter the code or text, then you need to add a prominent notification that indicates where you have made changes.\n",
    "\n",
    "This code, markdown text, and sample dataset can be cited using the following details:\n",
    "\n",
    "_Wallis, I.C. and McLean, K. (2021) Geothermal Well Test Analysis with Python, Software Underground Transform 2021 Tutorial, https://github.com/ICWallis/T21-Tutoral-WellTestAnalysis_\n",
    "\n",
    "***\n",
    "\n",
    "## 1.1 A definition for geothermal\n",
    "\n",
    "In this tutorial, we discuss ‘conventional’ geothermal systems where a localised heat source (e.g., shallow crustal magma) or high background heat flow produces a plume of heated fluid that rises buoyantly towards the surface. The hot fluids that are close enough to the surface to be intersected by drilling (a few km) are the conventional geothermal reservoir (Figure 1). At a large scale, we think of these geothermal systems as convection cells that are recharged by regional groundwater. However, they more resemble a thermal conveyer belt at the reservoir scale because fluid enters the hot, productive reservoir though one or more deep upflows and exists though one or more shallow outflow zones. We do not discuss engineered (hot dry rock) geothermal systems or low-temperature sedimentary aquifers. However, the testing methods used in those settings are similar to those described in this tutorial.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image('https://raw.githubusercontent.com/ICWallis/T21-Tutoral-WellTestAnalysis/main/Figures/Figure1.png',width = 800,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 1: Cross-section of conventional geothermal reservoir, showing rising plume of buoyant fluid (from Zarrouk and McLean, 2019 and reproduced from Brian Lovelock, Jacobs Ltd. with kind premission)._\n",
    "\n",
    "For geothermal reservoir engineering, it is useful to classify conventional geothermal systems by enthalpy because it informs on the dominant heat transfer mechanism at work in the reservoir: conduction, convection, or advection (Table 1). \n",
    "\n",
    "_Table 1: Classification for geothermal systems by enthalpy (from Kaya et al., 2011)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('https://raw.githubusercontent.com/ICWallis/T21-Tutoral-WellTestAnalysis/main/Figures/Table1.png',width = 650,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## 1.2 Introduction to geothermal wells\n",
    "\n",
    "Geothermal wells completions differ significantly from petroleum wells that are  typically only perforated over very short intervals (i.e., have limited access into the reservoir). Geothermal wells have very long perforated intervals with access to the reservoir, often in excess of 1000 metres in length (Figure 2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('https://raw.githubusercontent.com/ICWallis/T21-Tutoral-WellTestAnalysis/main/Figures/Figure2.jpg',width = 500,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 2: Schematic of geothermal well showing feed zones within the production zone accessing the wellbore via the perforated liner (McLean and Zarrouk, 2019)._\n",
    "\n",
    "Geothermal wells will self-discharge if there is sufficient temperature to generate boiling. In these conditions, flow is driven by the volume expansion of water during boiling rather than high pressures as is the case in groundwater wells. Geothermal wells that are too cool to boil will still flow if there is sufficient hydrostatic head, such as in mountainous areas. Otherwise, these wells are pumped. Pressure gradients in liquid-dominated reservoirs are typically hot hydrostatic (i.e., at a lower pressure than the regional cold hydrostatic gradient). In other words, the pressure is lower inside the reservoir than outside – counter-intuitive but true. \n",
    "\n",
    "***\n",
    "\n",
    "## 1.3 Introduction to well testing\n",
    "\n",
    "A geothermal well is typically drilled over a period of a few weeks. Immediately after drilling is completed, a program of testing commences. The typical testing sequence is: completion testing, then heating runs, and finally output testing. \n",
    "\n",
    "The **completion test** captures pressure, temperature and spinner (PTS) data using a downhole PTS tool (Figure 3). This tool is suspended in the wellbore on a wireline whilst cold water is injected into the well at different rates through the side valve (Figure 4). \n",
    "\n",
    "The main objectives of completion testing are to:\n",
    "1. Identify permeable feed zones in the well, including whether there is a dominant feed zone.\n",
    "2. Gain an indication of the future potential of the well once in service. \n",
    "\n",
    "After completion testing is a set of **heating runs** are conducted in order to observe the pressure and temperature response of the well after cold water injection stops (hence heating commences). Typically at least three heating runs are acquired at increasingly time intervals (i.e., immediately after the completion test, then days later, then weeks or months later depending on the reservoir conditions). These data contribute to Objective 1 of completion testing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('https://raw.githubusercontent.com/ICWallis/T21-Tutoral-WellTestAnalysis/main/Figures/Figure3.png',width = 500,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 3: Pressure-temperature-spinner (PTS) tool, 2.6 metres in length (Zarrouk and McLean, 2019)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('https://raw.githubusercontent.com/ICWallis/T21-Tutoral-WellTestAnalysis/main/Figures/Figure4.png',width = 800,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Figure 4: Schematic of downhole tool suspended on wireline, including surface equipment setup (Zarrouk and McLean, 2019)._\n",
    "\n",
    "If the well is destined to be a production well, then it is subjected to output testing (production testing) after heating. Some injection wells are not output tested, as this will never be their function. Typically the well is discharged at multiple flow rates during the output test, while the mass flow and well head pressure recorded for each. From this a a single output curve is generated that shows the behaviour/potential of the well under various operating conditions. PTS data are also captured during discharge in order to see which of the feed zones are contributing to the flow, and how much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Google Colab Setup\n",
    "\n",
    "If you are using Google Colab to run this notebook, we assume you have already followed the Google Colab setup steps outlined [here](https://github.com/ICWallis/T21-Tutoral-WellTestAnalysis).\n",
    "\n",
    "Because we are importing data, we need to \"mount your Google Drive\", which is where we tell this notebook to look for the data files. You will need to mount the Google Drive into each notebook.  \n",
    "\n",
    "1. Run the cell below. If you are not in Google Colab, running the cell below will just return an error that says \"No module named 'google'\"\n",
    "\n",
    "2. Follow the link generated by running this code. That link will ask you to sign in to your google account (use the one where you have saved these tutorial materials in) and to allow this notebook access to your google drive. \n",
    "\n",
    "3. Completing step 2 above will generate a code. Copy this code, paste below where it says \"Enter your authorization code:\", and press ENTER. \n",
    "\n",
    "Congratulations, this notebook can now import data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "vyvITGydI6VKaRm9mgYw",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "***\n",
    "\n",
    "# 2. Import and munge test data\n",
    "\n",
    "We are working with two sources of data:\n",
    "\n",
    "1. Pumps operating at the surface (datetime and flow rate)\n",
    "2. PTS tool in the well (datetime, pressure, temperature, spinner, other tool information)\n",
    "\n",
    "The following steps take the raw data that has been provided as excel files, imports them as a Pandas dataframe (one called flowrate and the other called pts), and then do some manipulation to generate a nice clean dataset that we can work with.\n",
    "\n",
    "We will see that data format and data quality are common challenges, especially when datetime is involved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "fzhYT0MO62SDrzOn7cJU",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "uqztHbtVc5988bBogcPK",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "***\n",
    "\n",
    "## 2.1. Pump (flowrate) data\n",
    "\n",
    "We will turn the excel data into a Pandas dataframe that includes:\n",
    "- A datetime field we can use with the tool data\n",
    "- Flowrate in the units we need\n",
    "\n",
    "### 2.1.1 Import flowrate data using Pandas\n",
    "\n",
    "We read the data in with the header location defined as row 1. This automatically skips row 0 which just contains some text that we don’t want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "8ZwGDJaSxQPeSbTIxYGb",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "# Use this method if you are running this notebook in Google Colab\n",
    "flowrate = pd.read_excel(r'/content/drive/My Drive/T21-Tutoral-WellTestAnalysis-main/Data-FlowRate.xlsx', header=1) \n",
    "\n",
    "# Use this method if you are running this notebook locally (Anaconda)\n",
    "#flowrate = pd.read_excel(r'Data-FlowRate.xlsx', header=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "oa7rQShwgVulOwZU9OM1",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### Some useful Pandas methods\n",
    "\n",
    "We will regularly use a set of Pandas methods to check our data as we munge it\n",
    "\n",
    "\n",
    "Display the first few rows of the dataframe\n",
    "    \n",
    "    df.head() _or_ df.head(n) _to show n rows_\n",
    "\n",
    "Display the last few rows of the dataframe\n",
    "    \n",
    "    df.tail() _or_ df.tail(n) _to show n rows_\n",
    "\n",
    "Useful information like the dataframe shape and the data types\n",
    "\n",
    "    df.info() \n",
    "\n",
    "A list of the column headers\n",
    "\n",
    "    df.columns \n",
    "\n",
    "Data types in each coloumn\n",
    "\n",
    "    df.dtypes\n",
    "\n",
    "Shape of the dataframe\n",
    "    \n",
    "    df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "4tZ9Gl0wQWFI7ijnmVMw",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.1.2 Rename coloums\n",
    "\n",
    "We do this to remove spaces from the column headers. \n",
    "\n",
    "This step is not compulsory, but the presence of spaces in the column names dictates the code format. Once a column has been created, we can interchangeably use the flowrate.raw_datetime or flowrate\\['raw_datetime'\\] notation. If there are spaces in the column names, the df.column_name notation will not work and we must use the df\\['column_name'\\] format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "eKtgA03HydCA0uLyYXXw",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "oKjD5qsfkr67QUdSPtZh",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "flowrate.columns = ['raw_datetime','flow_Lpm'] \n",
    "\n",
    "flowrate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "6UALm9tlOFKUfPGeXrD1",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.1.3 Convert datetime string into Python datetime \n",
    "\n",
    "The datetime is in [ISO format](https://en.wikipedia.org/wiki/ISO_8601) and, because it includes the timezone, this is the most globally useful datetime format. \n",
    "\n",
    "> 2020-12-11T06:00:00+13:00 \n",
    "\n",
    "where T indicates the time data and +13:00 is the time shift between UTC and New Zealand where the pumps were recording data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "UMOYivfmlsT5uwXUgBam",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "d9ApL7ka0TLoVpQfhBGl",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "flowrate.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "oNChvnBk8WhtVZ1SE0CB",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "Look at the output above and note that the _raw_datetime_ data type is _object_ and not _datetime_\n",
    "\n",
    "We will use a two-step process to parse this date:\n",
    "\n",
    "1. Convert it to a datetime object with the default UTC timezone\n",
    "2. Convert the datetime object to local time in New Zealand so it can be combined with the pts tool data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "GSmCItetPA4lcUWIc6Mr",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "wps30zPxFpkDfUYIZvLK",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "# use a method that recognises the ISO format to parse the datetime\n",
    "\n",
    "list = []\n",
    "for date in flowrate['raw_datetime']:\n",
    "    newdate = datetime.fromisoformat(date)\n",
    "    list.append(newdate)\n",
    "flowrate['ISO_datetime'] = list\n",
    "\n",
    "flowrate.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Z1HpdAPxByXm6cwO0mH9",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "The method fromisoformate() is new in version Python 3.7\n",
    "\n",
    "More information can be found [here](https://docs.python.org/3/library/datetime.html) and [here](https://pythontic.com/datetime/date/fromisoformat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "cN1zAqBgLrFXeWl2ewh4",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "HjM8TtUcx5nEE18oyCeU",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "flowrate.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "gLHXFcogTjx32WZ1ukVe",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "Now we can see that the data type for the ISO_datetime column is a UTC datetime: datetime64\\[ns, UTC+13:00\\]\n",
    "\n",
    "But we need it in local NZ time to combine with the PTS tool data. Luckily, the datetime.strftime method recognises the timezone in the datetime object and does the conversion for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "0v4y7Vgf1Kk3nU1dly0s",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "ozvj6alLLxRsBXKmZEV1",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "list = []\n",
    "for date in flowrate.ISO_datetime:\n",
    "    newdate = pd.to_datetime(datetime.strftime(date,'%Y-%m-%d %H:%M:%S'))\n",
    "    list.append(newdate)\n",
    "flowrate['datetime'] = list\n",
    "\n",
    "flowrate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "FEI0b0CF8e97mR4dIlDW",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "E2x1QVx9Bf9L8CI5jLSK",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "flowrate.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "2xMy7jklX0ttWcCodNhI",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "Now we have a Python datetime object that we can combine with the PTS data which does not have timezone information.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "TdfwOipkuBaMv9J6chB0",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.1.4 Add a flowrate field in our desired units\n",
    "\n",
    "Conversions for typical geothermal flowrate units:\n",
    "\n",
    "- L/sec to t/hr 3.6\n",
    "- L/min to t/hr 0.060"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "CnjuFrYMqykDuSncZxLQ",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "IwEfURBLENlMDxGbPhHY",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "flowrate['flow_tph'] = flowrate.flow_Lpm * 0.060\n",
    "\n",
    "flowrate.head(2) # 23 to see the non-zero values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "ta9ZGOwx2AF0jJTapJXm",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.1.5 Trim excess coloumns from the dataframe\n",
    "\n",
    "Now we just drop the columns that we don't want from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Z5BeJep3J0arDpMG7vgK",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "AOgicogofOegrmOdzsdR",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "flowrate.drop(columns = ['raw_datetime', 'flow_Lpm', 'ISO_datetime'], inplace = True)\n",
    "\n",
    "flowrate.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "FgbXhODGUvvCn8scSgm9",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### inplace = True\n",
    "\n",
    "Each time we do something something like drop columns, we generate a new Pandas dataframe. \n",
    "\n",
    "The argument inplace=True overwrites the old dataframe with the new one but we could have achieved the same thing with assignment:\n",
    "\n",
    "    flowrate = flowrate.drop(columns = \\['raw_datetime', 'flow_Lpm', 'ISO_datetime'\\])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "t9gODXgfeg3u2jB8caNN",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "***\n",
    "## 2.2 Pressure, temperature, spinner tool data\n",
    "\n",
    "We will use a similar process as above to import and munge the pressure, temperature, and spinner (PTS) tool data. However, the PTS dataset includes an addional challenge generated by bad data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "fPhzrLCveToiLcp4irH6",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.1.1 Import pts data using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "qjg1JHDkdiGjwyJpPhJr",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "# Use this method if you are running this notebook in Google Colab\n",
    "pts = pd.read_excel(r'/content/drive/My Drive/T21-Tutoral-WellTestAnalysis-main/Data-PTS.xlsx', header=1) \n",
    "\n",
    "# Use this method if you are running this notebook locally (Anaconda)\n",
    "#pts = pd.read_excel(r'Data-PTS.xlsx') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "hJqA87e8qnENyFl5Dxgx",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "If you run the cell below, you will see that we have a lot of data in the pts dataframe (101294 rows and 26 columns). \n",
    "\n",
    "Efficient handling of large datasets is one of the reasons why Python is better for these kinds of analysis than excel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "o2aF4ilgTMPUV1gZE3MK",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "7LDvHYtBWuebvC1VwC2k",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "pts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "vE7AChtEXvSGuEmVibdG",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "MbecOikyjMGdnQsnNJGr",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "pts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "zqaRobh9cafbhPffMunC",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.2.2 Rename selected coloumn headders\n",
    "\n",
    "The dataframe has a row of units below the header row that we need to remove. But because we want to know the units of our data, we will rename key columns to remove spaces and include units before dropping the row containing the units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "y24b1eb6Li0YEBYS5vG7",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "aumVZW6zJiRslAPDGmLG",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "# dictionary method for renaming some coloums\n",
    "dict = {\n",
    "    'DEPTH':'depth_m',\n",
    "    'SPEED': 'speed_mps',\n",
    "    'Cable Weight': 'cweight_kg',\n",
    "    'WHP': 'whp_barg',\n",
    "    'Temperature': 'temp_degC',\n",
    "    'Pressure': 'pressure_bara',\n",
    "    'Frequency': 'frequency_hz'\n",
    "}\n",
    "\n",
    "pts.rename(columns=dict, inplace=True)\n",
    "\n",
    "pts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "KUIs5bIGnU7nwcyjg0M4",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.2.3 Drop units row\n",
    "\n",
    "Note that we are using the index value to drop the row of units and then we remake the index. Therefore, if we run this cell over and over, it will keep dropping the first row of data. \n",
    "\n",
    "If you are unsure what state your dataframe is in or how many times you have run the cell below, it is useful to run the process from the start again (i.e., go back to step _2.1.1 Import pts data using Pandas_ and work down from there). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "yKhGTcuFlfb1MXZUqOpc",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "# drop units row using the index value of that row\n",
    "pts.drop(0, inplace=True)\n",
    "\n",
    "# re-index the dataframe\n",
    "pts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# WARNING if you run this cell again, it will drop the first line of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "9hZppMbdUS1BOXF7tEyc",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "Bg6FlJNGTkSldamIkVwW",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "pts.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "c6kQci575eLAExD4AD7b",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.2.4 Recognise bad datetime data & how to handle excel datetime floats\n",
    "\n",
    "If you investigate the _Time_ column in our pts dataframe, you'll find that the hours are all set to 00 despite the test running for nearly 12 hours and starting at around 9 in the morning. Unfortunately, these kinds of issues with bad data are common and they are why it's important to QA/QC of data when it is acquired. \n",
    "\n",
    "We will (reluctantly) use the excel timestamp to generate a new datetime.\n",
    "\n",
    "An excel timestamp is a floating-point number that reflects the number of days (or part thereof) since a specified start day. There are two systems that start counting from different dates (1900 and 1904) and some fundamental bugs in the way they are implemented. The start date is stored in the excel workbook and we need to know which system is used to correctly generate a datetime. Check out [this documentation](https://openpyxl.readthedocs.io/en/stable/datetime.html) for more information on the challenges of excel timestamps. **The short version is that we should avoid using excel float time whenever possible.** Unfortunately, it is not possible here because of the bad data.\n",
    "\n",
    "Because we have an xlsx file, will use the openpyxl package to determine the start date in the workbook and parse the excel float to datetime. If you have an xls file, then the xlrd module may be used to achieve the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "AawGiyc3mDUt4lBbgaih",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     },
     "outputId": {
      "block": "58AKGGPAd7hhkNkEuGa1",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "# first check the start day system in the workbook\n",
    "\n",
    "\n",
    "wb = openpyxl.load_workbook(filename=\"Data-PTS.xlsx\")\n",
    "\n",
    "if wb.epoch == openpyxl.utils.datetime.CALENDAR_WINDOWS_1900: \n",
    "    print(\"This workbook is using the 1900 date system.\")\n",
    "if wb.epoch == openpyxl.utils.datetime.CALENDAR_MAC_1904: \n",
    "    print(\"This workbook is using the 1904 date system.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "yTDlX3q51Kpndjkfmyf5",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "We can see in the printed statement above that we have the 1900 date system. Therefore, we can use the default arguments in the from_excel method in the openpyxl utilities. Refer to [the docs](https://openpyxl.readthedocs.io/en/stable/api/openpyxl.utils.datetime.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "qtWIyGqJO8uNrWTLZDRd",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "list = []\n",
    "for date in pts.Timestamp:\n",
    "    newdate = openpyxl.utils.datetime.from_excel(date)\n",
    "    list.append(newdate)\n",
    "pts['datetime'] = list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "PoybLiSuQXbma05ufSWM",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "YaZvGUz6pNTGF7GIRRpN",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "pts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "UyyGV5hK4JpMCahCJ1dY",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.2.5 Drop unwanted columns from dataframe\n",
    "\n",
    "There are a lot of columns we do not need for our analysis, so we will drop these\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "6HxBG4z9pCx8tnxvYO5S",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "Ve53uRR7NhQaxid3q3cL",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "pts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Erk1RogpaG6Aegzy2t9Q",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "pts.drop(columns = ['Date', 'Time', 'Timestamp','Reed 0',\n",
    "       'Reed 1', 'Reed 2', 'Reed 3', 'Battery Voltage', \n",
    "       'PRT Ref Voltage','SGS Voltage', 'Internal Temp 1', \n",
    "       'Internal Temp 2', 'Internal Temp 3','Cal Temp', \n",
    "       'Error Code 1', 'Error Code 2', 'Error Code 3',\n",
    "       'Records Saved', 'Bad Pages',], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "gMrtlMqPXvVDrOhFkpJz",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "93isGEShyLmonFuz4G2k",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "pts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "88VH5eY4eZQX5bcecLcl",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "### 2.2.6 Correct the data types\n",
    "\n",
    "Run the cell below and note that the data types are 'object'. This is because we had a mix of text and numeric when importing these data (remember the units row). We convert the dtype to numeric using the pd.to_numeric method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "qLAo1BwslqX1D8UF2S73",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "8m63jIAl9RBHai3MVCDl",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "pts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "VRSuF4viWEjCX0GCVc2e",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "0eJ5nwH6qKUMBLxzqapw",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "pts[\n",
    "    ['depth_m', 'speed_mps','cweight_kg','whp_barg','temp_degC','pressure_bara','frequency_hz']\n",
    "] = pts[\n",
    "    ['depth_m','speed_mps','cweight_kg','whp_barg','temp_degC','pressure_bara','frequency_hz']\n",
    "    ].apply(pd.to_numeric)\n",
    "\n",
    "pts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "K9uNLFcGSGa6PsZ38OnP",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "Because methods like ipywidget interactive plots only work with floats, we make and append the time in seconds that has elapsed since the start of the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "f3asV84UY4eSjbkKVkwo",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "Aay9PHjktCh1tVSEKfzs",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "def timedelta_seconds(dataframe_col, test_start):\n",
    "    '''\n",
    "    Make a float in seconds since the start of the test\n",
    "\n",
    "    args:   dataframe_col: dataframe column containing datetime objects\n",
    "            test_start: test start time formatted '2020-12-11 09:00:00'\n",
    "\n",
    "    returns: float in seconds since the start of the test\n",
    "    '''\n",
    "    test_start_datetime = pd.to_datetime(test_start)\n",
    "    list = []\n",
    "    for datetime in dataframe_col:\n",
    "        time_delta = datetime - test_start_datetime\n",
    "        seconds = time_delta.total_seconds()\n",
    "        list.append(seconds)\n",
    "    return list\n",
    "\n",
    "test_start_datetime = '2020-12-11 09:26:44.448'\n",
    "\n",
    "flowrate['timedelta_sec'] = timedelta_seconds(flowrate.datetime, test_start_datetime)\n",
    "pts['timedelta_sec'] = timedelta_seconds(pts.datetime, test_start_datetime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "HLPqU2TgEzLnKlv2K2bX",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "***\n",
    "\n",
    "## We are finished importing and munging the data!\n",
    "\n",
    "We now have flowrate and pts dataframes that we can work with for the rest of our analysis. \n",
    "\n",
    "The steps taken above to import and munge the data are wrapped into custom functions in uitlities.py. \n",
    "\n",
    "In the rest of this tutorial, we will call these functions rather than stepping through the method again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "Q4Tvm3AoKAdLp6uDARaz",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "***\n",
    "\n",
    "# 3. Overview of the completion test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "CI4TXqnI6F35S6adihQ4",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "lvpExTofa3qR8Hr55Foy",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     }
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, 1,figsize=(18,12),sharex=True)\n",
    "\n",
    "ax1.plot(flowrate.datetime, flowrate.flow_tph, label='Surface pump flowrate', \n",
    "    c='k', linewidth=0.8, marker='.')\n",
    "ax1.set_ylabel('Surface flowrate [t/hr]')\n",
    "ax1.set_ylim(0,150)\n",
    "\n",
    "for ax in [ax2, ax3, ax4]:\n",
    "    ax.plot(pts.datetime, pts.depth_m, label='PTS tool depth', \n",
    "        c='k', linewidth=1.5)\n",
    "    ax.set_ylabel('PTS tool depth [m]')\n",
    "    ax.set_ylim(1000,0)\n",
    "\n",
    "ax4.set_xlabel('Time [hh:mm]')\n",
    "ax4.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    " \n",
    "injectivity_index = [ # purple\n",
    "    (pd.to_datetime('2020-12-11 10:28:00'),pd.to_datetime('2020-12-11 10:30:00')),\n",
    "    (pd.to_datetime('2020-12-11 12:51:00'),pd.to_datetime('2020-12-11 12:53:00')),\n",
    "    (pd.to_datetime('2020-12-11 15:20:00'),pd.to_datetime('2020-12-11 15:23:00')), # pumps shut off too soon\n",
    "    ]\n",
    "injectivity_index_alt = [ # light purple \n",
    "    (pd.to_datetime('2020-12-11 14:38:00'),pd.to_datetime('2020-12-11 14:40:00')) # alternate used because of pump issue\n",
    "    ]\n",
    "pressure_transient = [ # green\n",
    "    (pd.to_datetime('2020-12-11 10:36:00'),pd.to_datetime('2020-12-11 12:10:00')),\n",
    "    (pd.to_datetime('2020-12-11 12:55:15'),pd.to_datetime('2020-12-11 14:40:00')), \n",
    "    ]\n",
    "temperature_profile = [ # red\n",
    "    (pd.to_datetime('2020-12-11 10:03:00'),pd.to_datetime('2020-12-11 10:11:30')),\n",
    "    (pd.to_datetime('2020-12-11 12:28:30'),pd.to_datetime('2020-12-11 12:36:00')),\n",
    "    (pd.to_datetime('2020-12-11 14:57:30'),pd.to_datetime('2020-12-11 15:05:00')),\n",
    "    (pd.to_datetime('2020-12-11 16:09:00'),pd.to_datetime('2020-12-11 16:15:30'))\n",
    "    ]\n",
    "fluid_velocity = [ # yellow\n",
    "    (pd.to_datetime('2020-12-11 09:46:00'),pd.to_datetime('2020-12-11 10:25:00')),\n",
    "    (pd.to_datetime('2020-12-11 12:10:30'),pd.to_datetime('2020-12-11 12:51:00')),\n",
    "    (pd.to_datetime('2020-12-11 14:40:30'),pd.to_datetime('2020-12-11 15:19:00')),\n",
    "    ]\n",
    "\n",
    "ax1.set_title('Pressure transient analysis (not included in this tutorial)')\n",
    "for top, bottom in pressure_transient:\n",
    "    ax1.axvspan(top, bottom, color='#369a33', alpha=0.3) # green\n",
    "\n",
    "ax2.set_title('Temperature profile analysis - Notebook 2')\n",
    "for top, bottom in temperature_profile:\n",
    "    ax2.axvspan(top, bottom, color='#9a3336', alpha = 0.5) # red \n",
    "\n",
    "ax3.set_title('Determine well capacity (injectivity index) - Notebook 3')\n",
    "for top, bottom in injectivity_index:\n",
    "    ax3.axvspan(top, bottom, color='#33369a', alpha=.6) # purple\n",
    "\n",
    "for top, bottom in injectivity_index_alt:\n",
    "    ax3.axvspan(top, bottom, color='#33369a', alpha=.3) # light purple\n",
    "    \n",
    "ax4.set_title('Feed zones from fluid velocity analysis - Notebook 4')\n",
    "for top, bottom in fluid_velocity:\n",
    "    ax4.axvspan(top, bottom, color='#ffc000', alpha=.3) # yellow \n",
    "\n",
    "for ax in [ax1, ax2, ax3, ax4]:\n",
    "    ax.grid()\n",
    " \n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "KXVYFVFpvSjQlPX1RLDJ",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "#### Overview of the completion test (plot above)\n",
    "\n",
    "The highlighted areas on the plot above are the data we will extract for analysis during this tutorial. \n",
    "\n",
    "The zig-zags in the PTS tool depth shows the tool going up and down inside the well. Injectivity index (well capacity) uses pressure and flow rate just after these tool passes are complete but before the pump rate is changed (dark purple). However, after the third set of passes the pumps were shut off too soon, so we will use the pressure and flow rate for just prior the passes (light purple).\n",
    "\n",
    "#### Use the plot below to explore the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "qD1myV1lAmKgfdVTMneD",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     },
     "outputId": null
    }
   },
   "outputs": [],
   "source": [
    "def overview_fig(pts_df,flowrate_df,title=''):\n",
    "    fig, (ax1, ax2, ax3, ax4, ax5, ax6) = plt.subplots(6, 1,figsize=(10,15),sharex=True)\n",
    "    ax1.set_title(title,y=1.1,fontsize=15)\n",
    "\n",
    "    ax1.plot(flowrate_df.datetime, flowrate_df.flow_tph, label='Surface pump flowrate', \n",
    "        c='k', linewidth=0.8, marker='.')\n",
    "    ax1.set_ylabel('Surface flowrate [t/hr]')\n",
    "    ax1.set_ylim(0,150)\n",
    "    \n",
    "    ax2.plot(pts_df.datetime, pts_df.depth_m, label='PTS tool depth', \n",
    "        c='k', linewidth=0.8)\n",
    "    ax2.set_ylabel('PTS tool depth [m]')\n",
    "    ax2.set_ylim(1000,0)\n",
    "    \n",
    "    ax3.plot(pts_df.datetime, pts_df.pressure_bara, label='PTS pressure', \n",
    "        c='tab:blue', linewidth=0.8)\n",
    "    ax3.set_ylabel('PTS pressure [bara]')\n",
    "    \n",
    "    ax4.plot(pts_df.datetime, pts_df.temp_degC, label='PTS temperature', \n",
    "        c='tab:red', linewidth=0.8)\n",
    "    ax4.set_ylabel('PTS temperature')\n",
    "    \n",
    "    ax5.plot(pts_df.datetime, pts_df.frequency_hz, label='PTS impeller frequency', \n",
    "        c='tab:green', linewidth=0.8)\n",
    "    ax5.set_ylim(-30,30)\n",
    "    ax5.set_ylabel('PTS impeller frequency [hz]')\n",
    "    # 1 hz = 60 rpm\n",
    "\n",
    "    ax6.plot(pts_df.datetime, pts_df.speed_mps, label='PTS tool speed', \n",
    "        c='tab:orange', linewidth=0.8)\n",
    "    ax6.set_ylim(-2,2)\n",
    "    ax6.set_ylabel('PTS tool speed [mps]')\n",
    "    \n",
    "    ax6.set_xlabel('Time [hh:mm]')\n",
    "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "    \n",
    "    for ax in [ax1,ax2,ax3,ax4,ax5,ax6]:\n",
    "        ax.grid()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "iooxa": {
     "id": {
      "block": "WQQ69w4nTidvLmUqwXta",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 2
     },
     "outputId": {
      "block": "9t16BNSoskS43lU5FaEW",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "outputs": [],
   "source": [
    "overview_fig(pts,flowrate);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I sometimes use a ; at the end of the code in the cell to suppress extra output, as is has been done above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "iooxa": {
     "id": {
      "block": "5Ik5yRZrY0PRVf6o4g3U",
      "project": "KIIrxxLw2tcNx1nwyOJZ",
      "version": 1
     }
    }
   },
   "source": [
    "***\n",
    "\n",
    "### Cited references\n",
    "\n",
    "Kaya, E., Zarrouk, S.J., and O’Sullivan, M.J. (2011): Reinjection in geothermal fields: a review of worldwide experience. Renew. Sustain. Energy Rev. 15 (1), 47-68. \n",
    "\n",
    "Zarrouk, S.J. and McLean, K. (2019): Geothermal well test analysis: fundamentals, applications, and advanced techniques. 1st edition, Elsevier. \n",
    "\n",
    "***\n",
    "\n",
    "© 2021 [Irene Wallis](https://www.cubicearth.nz/) and [Katie McLean](https://www.linkedin.com/in/katie-mclean-25994315/) \n",
    "\n",
    "Licensed under the Apache License, Version 2.0\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "iooxa": {
   "id": {
    "block": "wCAs4DYex40xM0Q19AFK",
    "project": "KIIrxxLw2tcNx1nwyOJZ",
    "version": 2
   }
  },
  "kernelspec": {
   "display_name": "geothrm",
   "language": "python",
   "name": "geothrm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}